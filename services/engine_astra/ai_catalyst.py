import requests
import json
from shared.news_utils import fetch_news_rss

import os

# Helper to call Ollama
OLLAMA_HOST = os.environ.get('OLLAMA_HOST', 'ollama')
OLLAMA_URL = f"http://{OLLAMA_HOST}:11434/api/generate"
MODEL_NAME = "llama3"

def generate_ai_catalyst(ticker, news_items=None):
    """
    Analyzes news headlines to extract a Strategic Catalyst.
    Returns: (score, context)
        score: 0 (None), 1 (Good), 2 (Mega/Strategic)
        context: Description of the catalyst or None
    """
    
    if not news_items:
        try:
            news_items = fetch_news_rss(ticker)
        except Exception as e:
            print(f"AI Catalyst: News fetch failed for {ticker}: {e}")
            return 0, None

    if not news_items:
        return 0, None # No news, no catalyst

    # Prepare Context for LLM
    headlines = [f"- {item.get('title', '')}" for item in news_items[:8]] # Top 8 headlines
    headlines_text = "\n".join(headlines)

    prompt = f"""
    You are a financial analyst. Analyze these news headlines for {ticker} and identify ONE major "Catalyst Event".
    
    HEADLINES:
    {headlines_text}
    
    RULES:
    1. Identify the SINGLE most impactful event (e.g., Earnings Beat, Big Order Win, Acquisition, Product Launch, Demerger).
    2. Rate its impact "Score" as:
       - 2 (Mega/Strategic): Game changer (e.g., Merger, Huge Policy Support, Massive Order).
       - 1 (Good): Positive development (e.g., Decent Earnings, Partnership).
       - 0 (None): No clear major catalyst or negative news.
    
    OUTPUT FORMAT (JSON ONLY):
    {{
        "score": <0, 1, or 2>,
        "context": "<Short concise description of the event>"
    }}
    
    If no positive catalyst exists, return score 0.
    """
    
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False,
        "format": "json", # Force JSON mode if supported, else rely on prompt
        "options": {"temperature": 0.1}
    }
    
    try:
        response = requests.post(OLLAMA_URL, json=payload, timeout=120)
        if response.status_code == 200:
            res_json = response.json()
            llm_text = res_json.get('response', '')
            with open("debug_ai_log.txt", "w", encoding="utf-8") as f:
                f.write(f"LLM RESPONSE:\n{llm_text}\n")
            
            # Simple manual JSON parsing (robustness)
            import json
            try:
                # Try to find JSON object in text
                start = llm_text.find('{')
                end = llm_text.rfind('}') + 1
                if start != -1 and end != -1:
                    data = json.loads(llm_text[start:end])
                    score = int(data.get('score', 0))
                    context = data.get('context', 'Generated by AI')
                    
                    # Prefix context with score type for UI
                    if score == 2: prefix = "STRATEGIC (AI): "
                    elif score == 1: prefix = "GROWTH (AI): "
                    else: prefix = ""
                    
                    return score, prefix + context
                    
            except:
                print(f"AI Catalyst: JSON Parse Error for {ticker}. Raw: {llm_text}")
                
        return 0, None
        
    except Exception as e:
        with open("debug_ai_log.txt", "w", encoding="utf-8") as f:
            f.write(f"ERROR: Inference failed: {e}\n")
        print(f"AI Catalyst: Inference failed: {e}")
        return 0, None
